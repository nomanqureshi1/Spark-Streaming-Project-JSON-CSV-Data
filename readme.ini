Spark Streaming Project – JSON/CSV Data
Overview

This project demonstrates a simple Spark Structured Streaming pipeline in Python.

Continuously generates dummy JSON data.

Spark reads the JSON files as a stream.

Processes data in real-time and writes it to an output folder as CSV files.

You can also read all processed data into a single DataFrame.

Project Structure
Project-Spark_streaming/
├── input/                 # Folder where JSON files are generated
├── output/                # Folder where Spark writes processed CSV files
├── checkpoint/            # Folder used for Spark streaming checkpoints
├── generate_data.py       # Python script to create dummy JSON data
├── spark_stream.py        # Spark streaming script to read and process data
└── README.md              # Project documentation

Requirements

Python 3.x

Apache Spark 3.x (PySpark)

Jupyter Notebook or VS Code (optional, for development)